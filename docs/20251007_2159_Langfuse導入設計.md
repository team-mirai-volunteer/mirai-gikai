# Langfuse導入設計

## 概要

議案チャットエンドポイント（`web/src/app/api/chat/route.ts`）にLangfuseを導入し、プロンプト管理とテレメトリー機能を実装する。

## 目的

- プロンプトのバージョン管理をLangfuse管理画面で実施
- OpenTelemetryプロトコルによるトレーシング
- 開発/本番環境の統一的な管理とラベリング

## ブランチゴール

現在のシステムプロンプト（`route.ts`の87-107行目）の1つをLangfuseからリモート取得する実装を完了する。

## アーキテクチャ設計

### ディレクトリ構造

```
web/src/lib/llm/
├── langfuse/
│   ├── client.ts              # Langfuseクライアント初期化
│   └── types.ts               # 型定義
├── prompt/
│   ├── repository.ts          # Prompt取得のInterface定義
│   └── langfuse-repository.ts # Langfuse実装
└── index.ts                   # 公開API
```

### レイヤー構造

```
┌─────────────────────────────────────┐
│   API Route (/api/chat/route.ts)   │
└──────────────┬──────────────────────┘
               │
┌──────────────▼──────────────────────┐
│   Prompt Repository Interface       │
│   - getPrompt(name, variables?)     │
└──────────────┬──────────────────────┘
               │
        ┌──────▼──────┐
        │  Langfuse   │
        │ Repository  │
        └──────┬──────┘
               │
┌──────────────▼──────────────────────┐
│   Langfuse Client + OpenTelemetry   │
└─────────────────────────────────────┘
```

## インターフェース設計

### 1. PromptRepository Interface

```typescript
// web/src/lib/llm/prompt/repository.ts

export interface PromptVariables {
  [key: string]: string | number | boolean;
}

export interface PromptResult {
  content: string;
  version?: number;
  metadata?: Record<string, unknown>;
}

export interface PromptRepository {
  /**
   * プロンプトを取得する
   * @param name プロンプト名
   * @param variables テンプレート変数
   * @throws Error プロンプト取得失敗時
   */
  getPrompt(
    name: string,
    variables?: PromptVariables
  ): Promise<PromptResult>;
}
```

### 2. Langfuse実装

```typescript
// web/src/lib/llm/prompt/langfuse-repository.ts

import { Langfuse } from "langfuse";
import type { PromptRepository, PromptVariables, PromptResult } from "./repository";

export class LangfusePromptRepository implements PromptRepository {
  constructor(private client: Langfuse) {}

  async getPrompt(
    name: string,
    variables?: PromptVariables
  ): Promise<PromptResult> {
    try {
      const prompt = await this.client.getPrompt(name);
      const content = variables
        ? prompt.compile(variables)
        : prompt.prompt;

      return {
        content,
        version: prompt.version,
        metadata: {
          name: prompt.name,
          labels: prompt.labels,
        },
      };
    } catch (error) {
      throw new Error(
        `Failed to fetch prompt "${name}" from Langfuse: ${error instanceof Error ? error.message : String(error)}`
      );
    }
  }
}
```

### 3. Langfuseクライアント

```typescript
// web/src/lib/llm/langfuse/client.ts

import { Langfuse } from "langfuse";

let langfuseClient: Langfuse | null = null;

export function getLangfuseClient(): Langfuse {
  if (!langfuseClient) {
    const publicKey = process.env.LANGFUSE_PUBLIC_KEY;
    const secretKey = process.env.LANGFUSE_SECRET_KEY;
    const baseUrl = process.env.LANGFUSE_BASE_URL || "https://cloud.langfuse.com";

    if (!publicKey || !secretKey) {
      throw new Error(
        "Langfuse credentials not configured. Set LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY"
      );
    }

    langfuseClient = new Langfuse({
      publicKey,
      secretKey,
      baseUrl,
      release: process.env.VERCEL_ENV || "development",
      // OpenTelemetry統合は自動で有効化される
    });
  }

  return langfuseClient;
}
```

### 4. ファクトリー関数

```typescript
// web/src/lib/llm/index.ts

import { getLangfuseClient } from "./langfuse/client";
import { LangfusePromptRepository } from "./prompt/langfuse-repository";
import type { PromptRepository } from "./prompt/repository";

export function createPromptRepository(): PromptRepository {
  try {
    const client = getLangfuseClient();
    return new LangfusePromptRepository(client);
  } catch (error) {
    console.error("Failed to initialize Langfuse client:", error);
    throw error;
  }
}

// 型も公開
export type { PromptRepository, PromptVariables, PromptResult } from "./prompt/repository";
```

## API Route統合

### 修正箇所

`web/src/app/api/chat/route.ts` の `POST` 関数を以下のように修正：

```typescript
import { createPromptRepository } from "@/lib/llm";

export async function POST(req: Request) {
  const { messages } = await req.json();

  const billContext = messages[0]?.metadata?.billContext;
  const difficultyLevel = (messages[0]?.metadata?.difficultyLevel || "normal") as DifficultyLevelEnum;

  const promptRepo = createPromptRepository();

  try {
    // Langfuseからプロンプト取得
    const promptResult = await promptRepo.getPrompt("bill-chat-system", {
      billName: billContext?.name || "",
      billTitle: billContext?.bill_content?.title || "",
      billSummary: billContext?.bill_content?.summary || "",
      billContent: billContext?.bill_content?.content || "",
      difficultyInstructions: getDifficultyInstructions(difficultyLevel),
    });

    const result = streamText({
      model: "openai/gpt-4o-mini",
      system: promptResult.content,
      messages: convertToModelMessages(messages),
    });

    return result.toUIMessageStreamResponse();
  } catch (error) {
    console.error("Chat API error:", error);
    return new Response(
      JSON.stringify({
        error: "プロンプトの取得に失敗しました",
        details: error instanceof Error ? error.message : String(error)
      }),
      { status: 500, headers: { "Content-Type": "application/json" } }
    );
  }
}
```

## 環境変数設定

### `.env` に追加

```bash
# Langfuse Configuration
LANGFUSE_PUBLIC_KEY=pk-lf-xxx
LANGFUSE_SECRET_KEY=sk-lf-xxx
LANGFUSE_BASE_URL=https://cloud.langfuse.com

# 環境ラベル（Vercelでは自動設定される）
# VERCEL_ENV=production|preview|development
```

### 環境ラベリング

Vercelでは `VERCEL_ENV` が自動設定されるため、Langfuseの `release` パラメータとして使用：

- `production` - 本番環境
- `preview` - プレビュー環境（PR）
- `development` - ローカル開発

## OpenTelemetry統合

Langfuse SDKはOpenTelemetryを自動でサポートしているため、特別な設定は不要。

### トレース内容

自動で以下が記録される：

- プロンプト取得のレイテンシー
- LLMへのリクエスト/レスポンス
- トークン使用量
- エラー情報

### カスタムトレース（将来の拡張）

Langfuse SDKのトレース機能を使って、より詳細なトレーシングも可能：

```typescript
// 将来的な実装例
const trace = langfuse.trace({
  name: "bill-chat",
  metadata: {
    billId: billContext.id,
    difficultyLevel,
  },
});
```

## Langfuse管理画面でのプロンプト設定

### プロンプト名

`bill-chat-system`

### プロンプト内容（テンプレート）

```
あなたは日本の議案について説明する専門的なアシスタントです。

議案情報：
- 名称: {{billName}}
- タイトル: {{billTitle}}
- 要約: {{billSummary}}
- 詳細: {{billContent}}

{{difficultyInstructions}}

ルール：
1. この議案に関する質問にのみ回答する
2. 上記の難易度設定に従って説明する
3. 正確で客観的な情報を提供する
4. 政治的に中立な立場を保つ
5. 回答は600文字以下を目安にしつつ、フレンドリーかつサポーティブな口調で行う
6. 回答が難しい場合は、その旨を丁寧に伝える
7. メッセージのおわりは、会話の深堀りをサポートするような文章で締めくくる
8. ただし、毎回質問で終わると、不自然になるので、適宜調整する
```

### 変数

- `billName`: string
- `billTitle`: string
- `billSummary`: string
- `billContent`: string
- `difficultyInstructions`: string

### ラベル（推奨）

- `feature: chat`
- `version: v1`
- `language: ja`

## エラーハンドリング

### エラーケース

1. **Langfuse認証失敗**
   - クライアント初期化時にエラー
   - 500エラーを返却

2. **プロンプト取得失敗**
   - ネットワークエラー
   - プロンプト名が存在しない
   - 500エラーを返却

3. **テンプレート変数不足**
   - 警告ログを出力
   - 空文字列で置換して継続

### エラーレスポンス形式

```json
{
  "error": "プロンプトの取得に失敗しました",
  "details": "Failed to fetch prompt \"bill-chat-system\" from Langfuse: Network error"
}
```

## パッケージ依存関係

### 追加パッケージ

```json
{
  "dependencies": {
    "langfuse": "^3.x.x"
  }
}
```

※ Vercel AI SDKは既にインストール済み

## テスト戦略

### 統合テスト（手動）

1. Langfuse管理画面でプロンプト作成
2. ローカル環境で動作確認
3. Langfuse管理画面でプロンプト変更 → 反映されることを確認
4. エラーケース（認証失敗、プロンプト未存在）の確認

## 実装順序

1. パッケージインストール（`langfuse`）
2. ディレクトリ構造作成（`web/src/lib/llm/`）
3. インターフェース定義（`prompt/repository.ts`）
4. Langfuseクライアント（`langfuse/client.ts`）
5. Langfuse実装（`prompt/langfuse-repository.ts`）
6. ファクトリー関数（`index.ts`）
7. 型定義（`langfuse/types.ts`）
8. API Route統合（`app/api/chat/route.ts`）
9. 環境変数設定
10. Langfuse管理画面でプロンプト作成
11. 動作確認

## 将来的な拡張

### Phase 2（次フェーズ）

- 難易度別プロンプトもLangfuse管理に移行
- キャッシング機構の追加
- プロンプトバージョンの明示的指定

### Phase 3

- A/Bテスト機能
- プロンプトのパフォーマンス分析
- ユーザーフィードバック連携

## 参考資料

- [Langfuse Documentation](https://langfuse.com/docs)
- [Vercel AI SDK - OpenTelemetry](https://sdk.vercel.ai/docs/ai-sdk-core/telemetry)
- [OpenTelemetry JavaScript](https://opentelemetry.io/docs/instrumentation/js/)
